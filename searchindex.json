{"categories":[{"title":"blog","uri":"https://healinyoon.github.io/categories/blog/"},{"title":"ci/cd","uri":"https://healinyoon.github.io/categories/ci/cd/"},{"title":"devops","uri":"https://healinyoon.github.io/categories/devops/"},{"title":"jvm","uri":"https://healinyoon.github.io/categories/jvm/"},{"title":"msa","uri":"https://healinyoon.github.io/categories/msa/"}],"posts":[{"content":"Intro Kubernetesì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ í™˜ê²½ì„ êµ¬ì¶•í•˜ê³  ì‚¬ìš©í•´ë³´ì. ì—¬ê¸°ì„œëŠ” Kubernest í´ëŸ¬ìŠ¤í„°ê°€ êµ¬ì¶•ë˜ì–´ ìˆë‹¤ê³  ì „ì œí•˜ê³  ì§„í–‰í•œë‹¤. ì•„ì§ ì„¤ì¹˜ê°€ ë˜ì§€ ì•Šì•˜ë‹¤ë©´ Kubernetes Cluster ì„¤ì¹˜í•˜ê¸°(ubuntu18.04)ì„ ì°¸ê³ í•´ì„œ ì„¤ì¹˜ í›„ ì§„í–‰í•´ì•¼ í•œë‹¤.\n1. Nvidia Plugin Pod ìƒì„± ref)  Nvidia k8s-device-plugin ê³µì‹ ì‚¬ì´íŠ¸ Nvidia docker ê³µì‹ ì‚¬ì´íŠ¸  1.1 ê°€ì¥ ì •ë³´ê°€ ë§ì•˜ë˜ YAMLìœ¼ë¡œ ì„¤ì¹˜, ê·¸ëŸ¬ë‚˜ ì‹¤íŒ¨ ì²˜ìŒì— ì—¬ê¸° ë§í¬ë¥¼ ì°¸ê³ í•˜ì—¬ ì§„í–‰í–ˆë‹¤.\në‹¤ë§Œ ì•„ë˜ì™€ ê°™ì´ ë²„ì „ë§Œ ë³€ê²½í•˜ì—¬ ì‹¤í–‰í–ˆë‹¤.\n$ kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.12/nvidia-device-plugin.yml daemonset.extensions/nvidia-device-plugin- daemonset-1.12 created  í•˜ì§€ë§Œ ì•„ë˜ ì´ìŠˆ ë°œìƒí•´ì„œ ì‹¤íŒ¨í–ˆë‹¤ â†“ â†“ â†“\n1.2. ì´ìŠˆ 1.2.1. ì´ìŠˆ ë‚´ìš© ì¿ ë²„ë„¤í‹°ìŠ¤ 1.15 ë²„ì „ ì´í•˜ë¥¼ ì„¤ì¹˜í–ˆì„ ê²½ìš° ë¬¸ì œ ì—†ê² ì§€ë§Œ, 1.16 ë²„ì „ ì´ìƒì„ ì„¤ì¹˜í–ˆì„ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤.\nerror: unable to recognize \u0026quot;https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.12/nvidia-device-plugin.yml\u0026quot;: no matches for kind \u0026quot;DaemonSet\u0026quot; in version \u0026quot;extensions/v1beta1\u0026quot;  ì´ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ë²„ì „ì´ ì—…ê·¸ë ˆì´ë“œ ë˜ë©´ì„œ, Daemonsetì˜ extensions/v1beta1 ë²„ì „ì„ ë”ì´ìƒ ì§€ì›í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤.\nâ†’ 1) ë”°ë¼ì„œ ë²„ì „ì„ apps/v1 ìœ¼ë¡œ ë³€ê²½í•˜ê³  selector objectë¥¼ ì¶”ê°€í•œ í›„\nâ†’ 2) k8s-device-pluginì„ ë‹¤ì‹œ ì„¤ì¹˜í•˜ê³ \nâ†’ 3) ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ íŒŒì¼ë„ ì ì ˆí•˜ê²Œ ìˆ˜ì •í•´ì£¼ì—ˆë‹¤.\nref)  Kubectl convert ì°¸ê³  ìë£Œ No matches ì´ìŠˆ í•´ê²° ìë£Œ   (ì°¸ê³ ) Pod ìƒì„± ì‹¤íŒ¨ì‹œ ì—ëŸ¬ ì •ë³´ í™•ì¸\n $ kubectl describe pod {pod ëª…}  1.2.2. ë³€ê²½í•œ YAML íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ DaemonSet Pod ìƒì„± ì´ì œ ì»¤ìŠ¤í„° ë§ˆì´ì§•í•œ YAML íŒŒì¼ë¡œ Podë¥¼ ìƒì„±í•´ë³´ì.\n gpu-plugin.yaml\n apiVersion: apps/v1 kind: DaemonSet metadata: name: nvidia-device-plugin-daemonset-1.12 namespace: kube-system spec: updateStrategy: type: RollingUpdate selector: matchLabels: name: nvidia-device-plugin-ds template: metadata: # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler # reserves resources for critical add-on pods so that they can be rescheduled after # a failure. This annotation works in tandem with the toleration below. annotations: scheduler.alpha.kubernetes.io/critical-pod: \u0026quot;\u0026quot; labels: name: nvidia-device-plugin-ds spec: tolerations: # Allow this pod to be rescheduled while the node is in \u0026quot;critical add-ons only\u0026quot; mode. # This, along with the annotation above marks this pod as a critical add-on. - key: CriticalAddonsOnly operator: Exists - key: nvidia.com/gpu operator: Exists effect: NoSchedule containers: - image: nvidia/k8s-device-plugin:1.11 name: nvidia-device-plugin-ctr securityContext: allowPrivilegeEscalation: false capabilities: drop: [\u0026quot;ALL\u0026quot;] volumeMounts: - name: device-plugin mountPath: /var/lib/kubelet/device-plugins volumes: - name: device-plugin hostPath: path: /var/lib/kubelet/device-plugins nodeSelector: gpus: \u0026quot;true\u0026quot;  ìœ„ì˜ ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ ì£¼ìš” ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nâ‘  ë¦¬ì†ŒìŠ¤ ìœ í˜• = DaemonSet\nkind: DaemonSet  ë”°ë¼ì„œ ê¸°ë³¸ì ìœ¼ë¡œëŠ” ëª¨ë“  worker ë…¸ë“œ í•˜ë‚˜ì”© ë™ì‘í•˜ê²Œ í•œë‹¤.  â‘¡ RollingUpdate\nspec.selector.matchLabels.name\nname: nvidia-device-plugin-ds  spec.template.matadata.labels.name\nlabels: name: nvidia-device-plugin-ds  name objectê°€ nvidia-device-plugin-ds ì¸ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•˜ì—¬ RollingUpdateë¥¼ ì„¤ì •í•œë‹¤.\nâ‘¢ node Label ì§€ì •\nspec.template.spec.nodeSelector ë¡œ ì–´ëŠ ë…¸ë“œì˜ DaemonSetìœ¼ë¡œ ë„ì›Œì¤„ ê²ƒì¸ì§€ ë ˆì´ë¸”ë§í•´ì¤€ë‹¤.\nnodeSelector: gpus: \u0026quot;true\u0026quot;  1.3. gpu-plugin DeamonSet Pod ì •ìƒ ë™ì‘ í™•ì¸ $ kubectl -n kube-system get pod -l name=nvidia-device-plugin-ds NAME READY STATUS RESTARTS AGE nvidia-device-plugin-daemonset-1.12-d7t2g 1/1 Running 0 48d nvidia-device-plugin-daemonset-1.12-jmcg9 1/1 Running 0 48d nvidia-device-plugin-daemonset-1.12-zhsqm 1/1 Running 0 4h8mubectl -n kube-system get pod -l name=nvidia-device-plugin-ds NAME READY STATUS RESTARTS AGE nvidia-device-plugin-daemonset-1.12-7kh27 1/1 Running 0 27m $ kubectl -n kube-system logs -l name=nvidia-device-plugin-ds 2020/07/01 05:02:30 Loading NVML 2020/07/01 05:02:30 Fetching devices. 2020/07/01 05:02:30 Starting FS watcher. 2020/07/01 05:02:30 Starting OS watcher. 2020/07/01 05:02:30 Starting to serve on /var/lib/kubelet/device-plugins/nvidia.sock 2020/07/01 05:02:30 Registered device plugin with Kubelet  ğŸŒŸğŸŒŸ ì—¬ê¸°ì„œ ì ê¹! ğŸŒŸğŸŒŸ ì¤‘ìš”í•œ ì‚¬í•­ì€ gpuë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” Worker nodeê°€ gpus: \u0026quot;true\u0026quot; ë ˆì´ë¸”ë§ì´ ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤.\n ë§Œì•½ GPUê°€ ìˆëŠ” nodeì¸ë° í•´ë‹¹ DeamonSetì´ ì˜¬ë¼ê°€ìˆì§€ ì•Šê±°ë‚˜ ì‹ ê·œ Worker nodeë¥¼ ì¶”ê°€í•˜ë ¤ëŠ” ê²½ìš°  â‡’ kubectl label nodes {Worker node ëª…} gpus=true ë¡œ ë ˆì´ë¸”ë§ì„ í•´ì£¼ì.\n2. GPU ê°œìˆ˜ í™•ì¸ ì´ì œ ì¿ ë²„ë„¤í‹°ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜ë¥¼ í™•ì¸í•´ë³´ì.\nmaster nodeì—ì„œ ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ê° worker nodeì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜ê°€ ì¶œë ¥ëœë‹¤.\n$ kubectl get nodes \u0026quot;-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\\.com/gpu\u0026quot; NAME GPU gpu-1080ti-XX 9 gpu-1080ti-XX 9  3. Podì—ì„œ ê·¸ë˜í”½ ì¹´ë“œ ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸ 3.1. GPUë¥¼ ì‚¬ìš©í•˜ëŠ” Pod ìƒì„±í•˜ê¸° 3.1.1. YAML íŒŒì¼  gpu-k8s.yaml\n apiVersion: v1 kind: Pod metadata: name: gpu-k8s spec: containers: - name: gpu-container image: nvidia/cuda:9.0-runtime command: - \u0026quot;/bin/sh\u0026quot; - \u0026quot;-c\u0026quot; args: - nvidia-smi \u0026amp;\u0026amp; tail -f /dev/null resources: requests: nvidia.com/gpu: 2 limits: nvidia.com/gpu: 2  ###ref) nvidia/cuda ë„ì»¤ ì´ë¯¸ì§€ ë²„ì „ì´ ë§ì§€ ì•Šì€ ì´ìŠˆ ë°œìƒ ì‹œ â‡’ ë„ì»¤ í—ˆë¸Œì—ì„œ ë§ëŠ” ì´ë¯¸ì§€ ë²„ì „ì„ ì°¾ì•„ì„œ ì‚¬ìš©í•´ì£¼ë©´ ëœë‹¤.\n Docker Hub Kubernetes Resource Requestì™€ Limitì˜ ì´í•´ Schedule GPUs  3.1.2. Pod ìƒì„± ë° í™•ì¸ $ kubectl apply -f gpu-k8s.yaml pod/gpu-k8s created $ kubectl get pods NAME READY STATUS RESTARTS AGE gpu-k8s 1/1 Running 0 12s  3.1.3. nvidia-smi í™•ì¸ $ kubectl logs gpu-k8s Thu Jul 2 06:00:24 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.95.01 Driver Version: 440.95.01 CUDA Version: 10.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 108... Off | 00000000:86:00.0 Off | N/A | | 29% 30C P8 8W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 GeForce GTX 108... Off | 00000000:AF:00.0 Off | N/A | | 29% 31C P8 8W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+  3.2. 2ê°œì˜ Podë¥¼ ë„ì›Œì„œ gpu 4ê°œë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ê¸° gpu-k8s2.yaml ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ íŒŒì¼ì„ í•˜ë‚˜ ë” ë§Œë“¤ì–´ì„œ ìœ„ì™€ ë™ì¼í•˜ê²Œ ì‹¤í–‰í•´ë³´ì.\n3.2.1. ê²°ê³¼ í™•ì¸ $ kubectl get pods NAME READY STATUS RESTARTS AGE gpu-k8s 1/1 Running 0 2m44s gpu-k8s2 1/1 Running 0 2  3.2.2. nvidia-smi í™•ì¸ $ kubectl logs gpu-k8s2 Thu Jul 2 06:03:06 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.95.01 Driver Version: 440.95.01 CUDA Version: 10.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 108... Off | 00000000:18:00.0 Off | N/A | | 29% 31C P8 7W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 GeForce GTX 108... Off | 00000000:3B:00.0 Off | N/A | | 29% 33C P8 8W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+  3.3. ì»¨í…Œì´ë„ˆê°€ ë…¸ë“œì˜ ëª¨ë“  GPUë¥¼ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•˜ê³  ì‹¶ë‹¤ë©´  requestì™€ limit ì„¤ì • ë¶€ë¶„ì„ ì—†ì• ì£¼ë©´ ëœë‹¤. íŠ¹ì´í•œ ì ì€ ì´ë¯¸ ë‹¤ë¥¸ íŒŒë“œì— GPUë¥¼ ëª¨ë‘ í• ë‹¹ í•´ì¤€ ìƒíƒœì—ì„œë„ íŒŒë“œ ìƒì„± ê°€ëŠ¥í•˜ë‹¤.  3.3.1. YAML íŒŒì¼ apiVersion: v1 kind: Pod metadata: name: gpu-all spec: containers: - name: gpu-container image: nvidia/cuda:9.0-runtime env: - name: DP_DISABLE_HEALTHCHECKS value: \u0026quot;xids\u0026quot; command: - \u0026quot;/bin/sh\u0026quot; - \u0026quot;-c\u0026quot; args: - nvidia-smi \u0026amp;\u0026amp; tail -f /dev/null  3.3.2. Pod ì‹¤í–‰ $ kubectl apply -f gpu-all.yaml pod/gpu-all created  3.3.3. í™•ì¸ $ kubectl get pods NAME READY STATUS RESTARTS AGE gpu-all 1/1 Running 0 50s gpu-k8s 1/1 Running 0 42m gpu-k8s2 1/1 Running 0 40m $ kubectl logs gpu-all Thu Jul 2 06:42:25 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.95.01 Driver Version: 440.95.01 CUDA Version: 10.2 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 108... Off | 00000000:18:00.0 Off | N/A | | 29% 32C P8 7W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 1 GeForce GTX 108... Off | 00000000:3B:00.0 Off | N/A | | 29% 33C P8 8W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 2 GeForce GTX 108... Off | 00000000:86:00.0 Off | N/A | | 29% 31C P8 8W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ | 3 GeForce GTX 108... Off | 00000000:AF:00.0 Off | N/A | | 29% 31C P8 8W / 250W | 0MiB / 11178MiB | 0% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+  ","id":0,"section":"posts","summary":"Intro Kubernetesì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ í™˜ê²½ì„ êµ¬ì¶•í•˜ê³  ì‚¬ìš©í•´ë³´ì. ì—¬ê¸°ì„œëŠ” Kubernest í´ëŸ¬ìŠ¤í„°ê°€ êµ¬ì¶•ë˜ì–´ ìˆë‹¤ê³  ì „ì œí•˜ê³  ì§„í–‰í•œë‹¤. ì•„ì§ ì„¤ì¹˜ê°€ ë˜ì§€ ì•Šì•˜","tags":["docker","kubernetes"],"title":"Kubernets(ì¿ ë²„ë„¤í‹°ìŠ¤) with GPU êµ¬ì¶•í•˜ê¸°","uri":"https://healinyoon.github.io/2020/10/20201023_kubernetes_with_gpu/","year":"2020"},{"content":"Intro íšŒì‚¬ì—ì„œ ì¿ ë²„ë„¤í‹°ìŠ¤ ì—…ë¬´ë¥¼ í•˜ë‹¤ê°€ \u0026ldquo;ì»¨í…Œì´ë„ˆ ìœ„ì—ì„œë„ GPU ì„±ëŠ¥ì´ ë³´ì¥ë˜ëŠ”ê°€?\u0026ldquo;ë¼ëŠ” ì§ˆë¬¸ì´ ë‚˜ì™”ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ ìš´ì˜ ì¤‘ì— ìì£¼ ë§ˆì£¼í•˜ëŠ” ì§ˆë¬¸ì´ë¯€ë¡œ, ì´ë²ˆ ê¸°íšŒì— ì •ë¦¬ë¥¼ í•´ë³´ë ¤ê³  í•œë‹¤.\n[ ëª©ì°¨ ]  Infra workstation ì •ë³´ T4 ì •ë³´ T4 - Host ì„¤ì • T4 - Container ì„¤ì • T4 - Host vs Container ì„±ëŠ¥ ë¹„êµ ìƒì„¸ - Host ìƒì„¸ - Container  [ ìš”ì•½ ] ê²°ë¡  GPU on Host VS Containerë¥¼ ë¹„êµí•˜ì˜€ì„ ë•Œ ì†ë„ì˜ ì„±ëŠ¥ ì°¨ì´ê°€ ì—†ì—ˆìŒ\nìƒì„¸ ë‚´ìš©  GPU Performance on Host VS Container ë¹„êµì‹œ ì •í™•ë„ì—ëŠ” ì°¨ì´ê°€(ëª¨ë¸ì´ ê°™ìœ¼ë¯€ë¡œ) ì—†ìœ¼ë¯€ë¡œ, ì†ë„ë§Œ ë¹„êµí•˜ì˜€ë‹¤. GPUë¥¼ 1ê°œ ì‚¬ìš©í•˜ì˜€ì„ ê²½ìš°ì™€ 2ê°œ ì‚¬ìš©í•˜ì˜€ì„ ê²½ìš°ë¥¼ ë‚˜ëˆ„ì–´ ë¹„êµí•˜ì˜€ë‹¤. ë™ì¼í•œ ì¡°ê±´ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤(íšŸìˆ˜)ë¥¼ ì´ 2íšŒì”© ìˆ˜í–‰í•˜ì˜€ë‹¤.  1. ì •ë³´ í™•ì¸ 2.1. GPU í˜„í™© GPU 0: Tesla T4 (UUID: GPU-f881729c-c452-b42b-fab6-ab0647359a66) GPU 1: Tesla T4 (UUID: GPU-9e53cd27-5256-0904-95f3-0e6b7b9cce1d) GPU 2: Tesla T4 (UUID: GPU-5491ddfe-3d4f-283c-800c-fbd7f99fd87f) GPU 3: Tesla T4 (UUID: GPU-c2184c80-a215-c6bb-7db1-5a9d37b66961)  2.2. ë„ì»¤ ë²„ì „ Version: 19.03.6  3. Host ì„¤ì • 3.1. ê°€ìƒí™˜ê²½ ìƒì„± - /home/ldccai/PerformTestEnv/performTestEnv # pip3 install virtualenv # virtualenv /home/ldccai/PerformTestEnv/performTestEnv  3.2. Tensorflow ì„¤ì¹˜ # source /home/ldccai/PerformanceTest/performTestEnv/bin/activate # python -m pip install --upgrade pip # sudo -H pip install --upgrade tf-nightly-gpu  3.3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‹¤í–‰ # source /home/ldccai/PerformanceTest/performTestEnv/bin/activate # cd /home/ldccai/PerformanceTest/ # git clone https://github.com/tensorflow/benchmarks.git # cd benchmarks  4. Container ì„¤ì • 4.1. ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ root@ubuntu:~# docker pull tensorflow/tensorflow:nightly-gpu  4.2. ì»¨í…Œì´ë„ˆ run with GPU root@ubuntu:~# docker container run -d --gpus all -it tensorflow/tensorflow:nightly-gpu 94515f052adbddf25bb9c66e5d5d7ee6a6010cfc74c6936f3b01bdf764202488  4.3. ì»¨í…Œì´ë„ˆ ì ‘ì† root@ubuntu:~# docker exec -it 94515f052adb /bin/bash \u0026quot;docker exec\u0026quot; requires at least 2 arguments. See 'docker exec --help'. Usage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...] Run a command in a running container root@ubuntu:~# docker container exec -it 94515f052adb /bin/bash ________ _______________ ___ __/__________________________________ ____/__ /________ __ __ / _ _ \\_ __ \\_ ___/ __ \\_ ___/_ /_ __ /_ __ \\_ | /| / / _ / / __/ / / /(__ )/ /_/ / / _ __/ _ / / /_/ /_ |/ |/ / /_/ \\___//_/ /_//____/ \\____//_/ /_/ /_/ \\____/____/|__/ WARNING: You are running this container as root, which can cause new files in mounted volumes to be created as the root user on your host machine. To avoid this, run the container by specifying your user's userid: $ docker run -u $(id -u):$(id -g) args...  4.4. íŒŒì´ì¬ ë²„ì „ í™•ì¸ root@282efcfdc3c8:/# python Python 3.6.9 (default, Apr 18 2020, 01:56:04) [GCC 8.4.0] on linux Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; import tensorflow as tf 2020-06-22 11:16:19.882107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1 \u0026gt;\u0026gt;\u0026gt; tf.__version__ '2.3.0-dev20200621'  4.5. git ì„¤ì¹˜ / ë¦¬í¬ì§€í† ë¦¬ ë‹¤ìš´ë¡œë“œ root@94515f052adb:/# apt-get install git root@94515f052adb:/# git clone https://github.com/tensorflow/benchmarks.git  5. T4 - Host vs Container ì„±ëŠ¥ ë¹„êµ 5.1. GPU 1ê°œ ì‚¬ìš© (performTestEnv) # CUDA_VISIBLE_DEVICES={GPU ë””ë°”ì´ìŠ¤} python tf_cnn_benchmarks.py --num_gpus=1 --batch_size={ë°°ì¹˜ì‚¬ì´ì¦ˆ} --model={ëª¨ë¸ëª…} --variable_update=parameter_server     í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤(íšŸìˆ˜) Host images/sec Container images/sec ë¹„ê³      1 124.77 126.95 model: Resnet50   2 125.76 125.07 model: Resnet50    5.2. GPU 2ê°œ ì‚¬ìš© (performTestEnv) # CUDA_VISIBLE_DEVICES={GPU ë””ë°”ì´ìŠ¤1, GPU ë””ë°”ì´ìŠ¤2} python tf_cnn_benchmarks.py --num_gpus=2 --batch_size={ë°°ì¹˜ì‚¬ì´ì¦ˆ} --model={ëª¨ë¸ëª…} --variable_update=parameter_server     í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤(íšŸìˆ˜) Host images/sec Container images/sec ë¹„ê³      1 242.60 240.64 model: Resnet50   2 241.52 236.72 model: Resnet50    6. ìƒì„¸ - Host 6.1. í…ŒìŠ¤íŠ¸ 1 6.1.1. ì¡°ê±´ (performTestEnv) # CUDA_VISIBLE_DEVICES=3 python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --model=resnet50 --variable_update=parameter_server (ì¤‘ëµ) Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -\u0026gt; physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5) TensorFlow: 2.3 Model: resnet50 Dataset: imagenet (synthetic) Mode: training SingleSess: False Batch size: 64 global 64 per device Num batches: 100 Num epochs: 0.00 Devices: ['/gpu:0'] // GPU 1ê°œ ì‚¬ìš© NUMA bind: False Data format: NCHW Optimizer: sgd Variables: parameter_server  6.1.2. ê²°ê³¼ Done warm up Step\tImg/sec\ttotal_loss 1\timages/sec: 127.9 +/- 0.0 (jitter = 0.0)\t7.608 10\timages/sec: 126.4 +/- 0.2 (jitter = 0.4)\t7.849 20\timages/sec: 126.3 +/- 0.1 (jitter = 0.5)\t8.013 30\timages/sec: 126.2 +/- 0.1 (jitter = 0.7)\t7.940 40\timages/sec: 126.0 +/- 0.1 (jitter = 0.7)\t8.137 50\timages/sec: 125.8 +/- 0.1 (jitter = 0.6)\t8.052 60\timages/sec: 125.6 +/- 0.1 (jitter = 0.7)\t7.782 70\timages/sec: 125.4 +/- 0.1 (jitter = 0.9)\t7.856 80\timages/sec: 125.3 +/- 0.1 (jitter = 1.0)\t8.011 90\timages/sec: 125.1 +/- 0.1 (jitter = 1.2)\t7.843 100\timages/sec: 124.8 +/- 0.1 (jitter = 1.4)\t8.090 ---------------------------------------------------------------- total images/sec: 124.77 ----------------------------------------------------------------  6.2. í…ŒìŠ¤íŠ¸ 2 6.2.1. ì¡°ê±´ (performTestEnv) # CUDA_VISIBLE_DEVICES=2,3 python tf_cnn_benchmarks.py --num_gpus=2 --batch_size=64 --model=resnet50 --variable_update=parameter_server (ì¤‘ëŸ‰) Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13968 MB memory) -\u0026gt; physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5) TensorFlow: 2.3 Model: resnet50 Dataset: imagenet (synthetic) Mode: training SingleSess: False Batch size: 128 global 64 per device Num batches: 100 Num epochs: 0.01 Devices: ['/gpu:0', '/gpu:1'] // GPU 2ê°œ ì‚¬ìš© NUMA bind: False Data format: NCHW Optimizer: sgd Variables: parameter_server  6.2.2. ê²°ê³¼ Done warm up Step\tImg/sec\ttotal_loss 1\timages/sec: 246.2 +/- 0.0 (jitter = 0.0)\t7.749 10\timages/sec: 244.9 +/- 0.6 (jitter = 1.7)\t7.892 20\timages/sec: 244.3 +/- 0.4 (jitter = 2.6)\t7.968 30\timages/sec: 244.5 +/- 0.4 (jitter = 2.3)\t7.934 40\timages/sec: 244.2 +/- 0.3 (jitter = 2.6)\t8.016 50\timages/sec: 243.8 +/- 0.3 (jitter = 2.6)\t7.922 60\timages/sec: 243.6 +/- 0.3 (jitter = 2.0)\t7.872 70\timages/sec: 243.5 +/- 0.2 (jitter = 1.9)\t7.837 80\timages/sec: 243.3 +/- 0.2 (jitter = 1.8)\t7.850 90\timages/sec: 243.0 +/- 0.2 (jitter = 2.1)\t7.859 100\timages/sec: 242.7 +/- 0.2 (jitter = 2.2)\t7.946 ---------------------------------------------------------------- total images/sec: 242.60 ----------------------------------------------------------------  7. ìƒì„¸ - Container 7.1. í…ŒìŠ¤íŠ¸ 1 7.1.1. ì¡°ê±´ root@94515f052adb:# CUDA_VISIBLE_DEVICES=3 python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --model=resnet50 --variable_update=parameter_server (ì¤‘ëµ) Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -\u0026gt; physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5) TensorFlow: 2.3 Model: resnet50 Dataset: imagenet (synthetic) Mode: training SingleSess: False Batch size: 64 global 64 per device Num batches: 100 Num epochs: 0.00 Devices: ['/gpu:0'] // GPU 1ê°œ ì‚¬ìš© NUMA bind: False Data format: NCHW Optimizer: sgd Variables: parameter_server  7.1.2. ê²°ê³¼ Done warm up Step\tImg/sec\ttotal_loss 1\timages/sec: 129.2 +/- 0.0 (jitter = 0.0)\t7.608 10\timages/sec: 128.7 +/- 0.4 (jitter = 0.9)\t7.849 20\timages/sec: 128.4 +/- 0.2 (jitter = 1.1)\t8.013 30\timages/sec: 128.4 +/- 0.2 (jitter = 0.8)\t7.940 40\timages/sec: 128.3 +/- 0.1 (jitter = 0.9)\t8.136 50\timages/sec: 128.1 +/- 0.1 (jitter = 0.9)\t8.053 60\timages/sec: 127.9 +/- 0.1 (jitter = 1.1)\t7.784 70\timages/sec: 127.7 +/- 0.1 (jitter = 1.4)\t7.859 80\timages/sec: 127.5 +/- 0.1 (jitter = 1.4)\t8.014 90\timages/sec: 127.3 +/- 0.1 (jitter = 1.4)\t7.842 100\timages/sec: 127.1 +/- 0.1 (jitter = 1.4)\t8.090 ---------------------------------------------------------------- total images/sec: 126.95 ----------------------------------------------------------------  7.2. í…ŒìŠ¤íŠ¸ 2 7.2.1. ì¡°ê±´ root@94515f052adb:# CUDA_VISIBLE_DEVICES=2,3 python tf_cnn_benchmarks.py --num_gpus=2 --batch_size=64 --model=resnet50 --variable_update=parameter_server (ì¤‘ëµ) Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13968 MB memory) -\u0026gt; physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5) TensorFlow: 2.3 Model: resnet50 Dataset: imagenet (synthetic) Mode: training SingleSess: False Batch size: 128 global 64 per device Num batches: 100 Num epochs: 0.01 Devices: ['/gpu:0', '/gpu:1'] // GPU 2ê°œ ì‚¬ìš© NUMA bind: False Data format: NCHW Optimizer: sgd Variables: parameter_server  7.2.2. ê²°ê³¼ Done warm up Step\tImg/sec\ttotal_loss 1\timages/sec: 240.6 +/- 0.0 (jitter = 0.0)\t7.749 10\timages/sec: 243.4 +/- 0.8 (jitter = 3.5)\t7.892 20\timages/sec: 243.3 +/- 0.5 (jitter = 2.7)\t7.968 30\timages/sec: 243.1 +/- 0.4 (jitter = 2.8)\t7.934 40\timages/sec: 242.6 +/- 0.3 (jitter = 2.3)\t8.019 50\timages/sec: 242.4 +/- 0.3 (jitter = 2.0)\t7.923 60\timages/sec: 242.1 +/- 0.3 (jitter = 1.8)\t7.878 70\timages/sec: 241.8 +/- 0.2 (jitter = 1.6)\t7.834 80\timages/sec: 241.5 +/- 0.2 (jitter = 1.6)\t7.861 90\timages/sec: 241.1 +/- 0.2 (jitter = 2.0)\t7.852 100\timages/sec: 240.8 +/- 0.3 (jitter = 2.1)\t7.948 ---------------------------------------------------------------- total images/sec: 240.64 ----------------------------------------------------------------  ","id":1,"section":"posts","summary":"Intro íšŒì‚¬ì—ì„œ ì¿ ë²„ë„¤í‹°ìŠ¤ ì—…ë¬´ë¥¼ í•˜ë‹¤ê°€ \u0026ldquo;ì»¨í…Œì´ë„ˆ ìœ„ì—ì„œë„ GPU ì„±ëŠ¥ì´ ë³´ì¥ë˜ëŠ”ê°€?\u0026ldquo;ë¼ëŠ” ì§ˆë¬¸ì´ ë‚˜ì™”ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ ìš´ì˜ ì¤‘ì— ìì£¼ ë§ˆì£¼","tags":["docker"],"title":"GPU ì„±ëŠ¥ ë¹„êµí•˜ê¸°: Host vs Container","uri":"https://healinyoon.github.io/2020/10/20201023_gpu_performance_host_vs_container/","year":"2020"},{"content":"ë°°ê²½ íšŒì‚¬ì—ì„œ Kubernetesë¥¼ ìš´ì˜í•˜ë‹¤ë³´ë©´ í´ëŸ¬ìŠ¤í„°ì— ìƒˆë¡œìš´ worker nodeë¥¼ ì¶”ê°€í•´ì•¼í•˜ëŠ” ì¼ì´ ì¢…ì¢… ìƒê¹ë‹ˆë‹¤.\në¬¸ì œëŠ” apt-get ë“± ê¸°ë³¸ íŒ¨í‚¤ì§€ ê´€ë¦¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê° ì—†ì´ ì„¤ì¹˜í•˜ë©´ ê¸°ì¡´ì— ìš´ì˜í•˜ë˜ k8s í´ëŸ¬ìŠ¤í„° ë²„ì „ê³¼ ë§ì§€ ì•Šì€ ìµœì‹  ë²„ì „ì´ ì„¤ì¹˜ ëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤\u0026hellip;(ê·¸ëŸ¬ë©´ ì €ì²˜ëŸ¼ ì‘ì—…ì„ 2ë²ˆ í•˜ê²Œ ë©ë‹ˆë‹¤)\nê·¸ëŸ°ë° ë°”ì´ë„ˆë¦¬ íŒŒì¼ì„ ì‚¬ìš©í•´ì„œ ì„¤ì¹˜í•˜ê¸°ëŠ” ë˜ ê·€ì°®ê³ ..\në”°ë¼ì„œ aptë¥¼ ì‚¬ìš©í•˜ë˜, ë²„ì „ì„ ì˜µì…˜ìœ¼ë¡œ ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ì¹˜ë¥¼ í•˜ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤.\në‚˜ì¤‘ì— ë˜ 2ë²ˆ ì‘ì—…í•˜ì§€ ì•Šê¸° ìœ„í•´ì„œ, ê·¸ë¦¬ê³  ì¤‘ê°„ì— ë°œìƒí•œ ì´ìŠˆë„ ê¸°ë¡í•´ë‘˜ê²¸ ë‚´ìš©ì„ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.\nì„¤ì¹˜í•˜ê¸° ì‚¬ì‹¤ ê¸°ì¡´ k8s í´ëŸ¬ìŠ¤í„° ì„¤ì¹˜ í”„ë¡œì„¸ìŠ¤ì™€ ë‹¤ë¥¸ ì ì€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ í”„ë¡œì„¸ìŠ¤ëŠ” ì—¬ê¸°ë¥¼ ì°¸ê³  ë°”ëë‹ˆë‹¤.\níŠ¹ì • ë²„ì „ ì„¤ì¹˜ ì˜µì…˜ì„ ì£¼ëŠ” ë¶€ë¶„ë§Œ ì‹ ê²½ì¨ì„œ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤.\n# cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl // íŒ¨í‚¤ì§€ê°€ ìë™ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ë˜ì§€ ì•Šë„ë¡ ì„¤ì • sudo apt-mark hold kubelet kubeadm kubectl  ì›ë˜ëŠ” ì•„ë˜ì™€ ê°™ì´ ê·¸ëƒ¥ ìµœì‹  ë²„ì „ì„ ì„¤ì¹˜í–ˆë‹¤ë©´ ì´ë²ˆì—” ì˜µì…˜ìœ¼ë¡œ ë²„ì „ì„ ì¤˜ì•¼ í•©ë‹ˆë‹¤. sudo apt-get install -y kubelet kubeadm kubectl  ìš´ì˜ ì¤‘ì¸ í´ëŸ¬ìŠ¤í„°ì˜ ë²„ì „ í™•ì¸í•˜ê¸° ë¨¼ì € ê¸°ì¡´ì— ìš´ì˜ ì¤‘ì¸ k8s í´ëŸ¬ìŠ¤í„°ì˜ ë²„ì „ì„ í™•ì¸í•©ë‹ˆë‹¤.\nroot@hci-k8s-master-01:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-worker-01 Ready \u0026lt;none\u0026gt; 74d v1.18.8 k8s-worker-02 Ready \u0026lt;none\u0026gt; 74d v1.18.8 k8s-master-01 Ready master 76d v1.18.6  í´ëŸ¬ìŠ¤í„°ì˜ nodeë“¤ì€ 1.18.x ë²„ì „ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në²„ì „ì„ í™•ì¸í–ˆìœ¼ë‹ˆ ì´ì œ ì„¤ì¹˜ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\nì„¤ì¹˜ ê°€ëŠ¥í•œ ë²„ì „ í™•ì¸í•˜ê¸° ì €ëŠ” sudo apt-get install -y kubelet=1.18.8 ì´ë ‡ê²Œ ì˜µì…˜ì„ ì£¼ê³  ì„¤ì¹˜í•˜ë ¤ê³  í–ˆëŠ”ë°, ì• ì„í•˜ê²Œë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\nì•„ë˜ì™€ ê°™ì€ ë¡œê·¸ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n# sudo apt-get install kubelet=1.18.8 Reading package lists... Done Building dependency tree Reading state information... Done E: Version '1.18.8' for 'kubelet' was not found  ì •í™•í•œ ë²„ì „ ì˜µì…˜ì„ í™•ì¸í•´ë³´ë„ë¡ í•©ë‹ˆë‹¤.\n# apt-cache madison kubeadm  ì¶œë ¥ ê²°ê³¼ì— ì œê°€ ì‚¬ìš©í•˜ë ¤ë˜ 1.18.8 ë²„ì „ì€ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì™€ìˆìŠµë‹ˆë‹¤.\nkubeadm | 1.18.8-00 | https://apt.kubernetes.io kubernetes-xenial/main amd64 Packages  1.18.8-00 ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜í•˜ê¸° ì´ì œ ë‹¤ì‹œ ì„¤ì¹˜ë¥¼ ì§„í–‰í•´ë´…ë‹ˆë‹¤.\nì›ë˜ kubeadmë§Œ ì„¤ì¹˜í•´ë„ kubectlê³¼ kubeletì´ ì˜ì¡´ì ìœ¼ë¡œ ì„¤ì¹˜ë©ë‹ˆë‹¤.\nê·¸ëŸ°ë° ë§ì…ë‹ˆë‹¤\u0026hellip; íŠ¹ì´ì ì´ ë°œìƒí•©ë‹ˆë‹¤.\n# sudo apt-get install kubeadm=1.18.8-00 Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: kubectl The following NEW packages will be installed: kubeadm kubectl 0 upgraded, 2 newly installed, 0 to remove and 5 not upgraded. Need to get 0 B/16.5 MB of archives. After this operation, 82.8 MB of additional disk space will be used. Do you want to continue? [Y/n] Y Selecting previously unselected package kubectl. (Reading database ... 128167 files and directories currently installed.) Preparing to unpack .../kubectl_1.19.2-00_amd64.deb ... Unpacking kubectl (1.19.2-00) ... Selecting previously unselected package kubeadm. Preparing to unpack .../kubeadm_1.18.8-00_amd64.deb ... Unpacking kubeadm (1.18.8-00) ... Setting up kubectl (1.19.2-00) ... Setting up kubeadm (1.18.8-00) ...  ìœ„ì™€ ê°™ì´ kubectlì´ 1.19.2-00 ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ê°€ ë©ë‹ˆë‹¤.\nì´ëŸ° ê²½ìš°, kubectlì„ downgrade í•´ì£¼ëŠ” ë°©ë²•ë„ ìˆì§€ë§Œ..\n# apt-get install kubectl=1.18.8-00  ì• ì´ˆì— ì²˜ìŒë¶€í„° ëª¨ë‘ ë²„ì „ì„ ì§€ì •í•´ì£¼ë©´ ë©ë‹ˆë‹¤.\n# sudo apt-get install -y kubelet=1.18.8-00 kubeadm=1.18.8-00 kubectl=1.18.8-00  Masterì— joiní•˜ê¸° ì°¸ê³ ì™€ ë™ì¼í•˜ê²Œ ì§„í–‰í•©ë‹ˆë‹¤.\n","id":2,"section":"posts","summary":"ë°°ê²½ íšŒì‚¬ì—ì„œ Kubernetesë¥¼ ìš´ì˜í•˜ë‹¤ë³´ë©´ í´ëŸ¬ìŠ¤í„°ì— ìƒˆë¡œìš´ worker nodeë¥¼ ì¶”ê°€í•´ì•¼í•˜ëŠ” ì¼ì´ ì¢…ì¢… ìƒê¹ë‹ˆë‹¤. ë¬¸ì œëŠ” apt-get ë“± ê¸°ë³¸ íŒ¨í‚¤ì§€ ê´€ë¦¬ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜","tags":["kubernetes"],"title":"Kuberenets íŠ¹ì • ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜í•˜ê¸°","uri":"https://healinyoon.github.io/2020/10/20201009_k8s_install_specific_version/","year":"2020"},{"content":"Kubernetes Cluster ì„¤ì¹˜í•˜ê¸° ì´ í˜ì´ì§€ì—ì„œëŠ” ubuntu18.04ì— kubeadm toolì„ ì„¤ì¹˜í•˜ê³  ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ kubernetes clusterë¥¼ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\nêµ¬ì„± H/W êµ¬ì„±í•˜ë ¤ëŠ” kubernetes clusterëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n   ë…¸ë“œ vCPU RAM Disk     master01 2 8GiB    worker01 2 8GiB    worker02 2 8GiB     Required ports 1) Control-plane node(s)\n2) Worker node(s)\nDocker ì„¤ì¹˜(ëª¨ë“  node) # curl -fsSL https://get.docker.com/ | sudo sh # systemctl start docker # systemctl enable docker  Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì„± ì¿ ë²„ë„¤í‹°ìŠ¤ ê³µì‹ ì‚¬ì´íŠ¸ kubeam ì„¤ì¹˜\nëª¨ë“  ë…¸ë“œì— ì•„ë˜ì˜ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.\n kubeadm: í´ëŸ¬ìŠ¤í„°ë¥¼ ë¶€íŠ¸ìŠ¤íŠ¸ë©í•˜ëŠ” ëª…ë ¹(ì¿ ë²„ë„¤í‹°ìŠ¤ ê´€ë¦¬) kubelet: í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ì‹œìŠ¤í…œì—ì„œ ì‹¤í–‰ë˜ëŠ” êµ¬ì„± ìš”ì†Œë¡œ, í¬íŠ¸ ë° ì»¨í…Œì´ë„ˆ ì‹œì‘ê³¼ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰(ì¿ ë²„ë„¤í‹°ìŠ¤ ì„œë¹„ìŠ¤) kubectl: í´ëŸ¬ìŠ¤í„°ì™€ í†µì‹ í•˜ê¸° ìœ„í•œ command line util(ì¿ ë²„ë„¤í‹°ìŠ¤ í´ë¼ì´ì–¸íŠ¸ í”„ë¡œê·¸ë¨, í´ëŸ¬ìŠ¤í„° êµ¬ì„±ê³¼ëŠ” ì „í˜€ ìƒê´€ ì—†ìŒ)  1) Kubernetes ë¦¬í¬ì§€í† ë¦¬ êµ¬ì„±(ëª¨ë“  node) # sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https curl curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -  2) Kubeadm, Kubelet, Kubectl ì„¤ì¹˜(ëª¨ë“  node) # cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl // íŒ¨í‚¤ì§€ê°€ ìë™ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ë˜ì§€ ì•Šë„ë¡ ì„¤ì • sudo apt-mark hold kubelet kubeadm kubectl // ë°ëª¬ ì¬ì‹œì‘ systemctl daemon-reload systemctl restart kubelet  3) hostname ë“±ë¡(ëª¨ë“  node) # sudo hostnamectl set-hostname master01 ë˜ëŠ” # sudo hostnamectl set-hostname worker01  4) /etc/hosts íŒŒì¼ ìˆ˜ì •(ëª¨ë“  node) # vi /etc/hosts ì•„ë˜ì— ì¶”ê°€ {IP} master01 {IP} worker01 {IP} worker02  5) Iptables ì„¤ì •(ëª¨ë“  node) ë¸Œë¦¿ì§€ ë˜ì–´ìˆëŠ” IPv4 íŠ¸ë˜í”½ì„ iptables ì²´ì¸ìœ¼ë¡œ ì „ë‹¬ë  ìˆ˜ ìˆë„ë¡ í•œë‹¤.\n# cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF # sudo sysctl --system  6) ìŠ¤ì™‘ ê¸°ëŠ¥ ë¹„í™œì„±í™”(ëª¨ë“  node) swap ë„ê¸° # sudo swapoff -a ì¬ë¶€íŒ… í›„ì—ë„ swap ì„¤ì • ìœ ì§€ # sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab  7) ë§ˆìŠ¤í„° ë…¸ë“œ ì´ˆê¸°í™” # kubeadm init  kubeadm init ëª…ë ¹ì–´ ì‹¤í–‰ì‹œ ì•„ë˜ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤.\nTo start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026quot;kubectl apply -f [podnetwork].yaml\u0026quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.1.11.4:6443 --token xxxxxxxxxxxxxxxxxxxxxxx \\ --discovery-token-ca-cert-hash sha256:e184c470296359bc4a35bc57624b03d8c4b3eb2bd46f413f3a68a86f182c9844  master nodeì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•˜ê³ \n$ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config  worker nodeì—ì„œ ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•˜ì—¬ master nodeì™€ joiní•œë‹¤.\nkubeadm join 10.1.11.4:6443 --token xxxxxxxxxxxxxxxxxxxxxxx \\ --discovery-token-ca-cert-hash sha256:e184c470296359bc4a35bc57624b03d8c4b3eb2bd46f413f3a68a86f182c9844  master nodeì—ì„œ kubectl get nodes ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥ëœë‹¤.\n# kubectl get nodes NAME STATUS ROLES AGE VERSION healin-k8s-master01 NotReady master 10m v1.19.0 healin-k8s-worker01 NotReady \u0026lt;none\u0026gt; 30s v1.19.0 healin-k8s-worker02 NotReady \u0026lt;none\u0026gt; 29s v1.19.0  8) ë„¤íŠ¸ì›Œí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì¹˜ pod ë„¤íŠ¸ì›Œí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì„¤ì¹˜í•´ì•¼ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ nodeê°„ í†µì‹ ì´ ê°€ëŠ¥í•˜ë‹¤.\nì‚¬ìš© ê°€ëŠ¥í•œ ë„¤íŠ¸ì›Œí¬ ì˜µì…˜ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\në‹¤ìŒ ëª…ë ¹ì„ master nodeì—ì„œ ìˆ˜í–‰í•˜ì—¬ weave pod ë„¤íŠ¸ì›Œí¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì„¤ì¹˜í•œë‹¤.\nkubectl apply -f \u0026quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\u0026quot; ì´ëŸ° ì˜¤ë¥˜ ë°œìƒì‹œ The connection to the server localhost:8080 was refused - did you specify the right host or port? export KUBECONFIG=/etc/kubernetes/admin.conf ì„ ì ìš©í•´ë³´ì  master nodeì—ì„œ kubectl get nodes ëª…ë ¹ì–´ë¥¼ ì ì‹œ í›„ ë‹¤ì‹œ ì…ë ¥í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ STATUSê°€ NotReady =\u0026gt; Readyë¡œ ë³€ê²½ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n# kubectl get nodes NAME STATUS ROLES AGE VERSION healin-k8s-master01 Ready master 17m v1.19.0 healin-k8s-worker01 Ready \u0026lt;none\u0026gt; 7m42s v1.19.0 healin-k8s-worker02 Ready \u0026lt;none\u0026gt; 7m41s v1.19.0  9) master nodeë¥¼ worker nodeë¡œë„ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´, ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì˜ control-plane ë…¸ë“œëŠ” ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ê²©ë¦¬ë˜ì–´ ìˆë‹¤(ê¸°ë³¸ê°’).\nmaster nodeì—ì„œëŠ” pod ê°€ ìŠ¤ì¼€ì¤„ë§ ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 1ëŒ€ì˜ ë¨¸ì‹ ìœ¼ë¡œë§Œ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•  ê²½ìš° ê²©ë¦¬ í•´ì œí•´ì•¼ í•œë‹¤.\n$ kubectl taint nodes â€“all node-role.kubernetes.io/master-  Control plane node isolationì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ê²½ë¡œë¥¼ ì°¸ê³ í•œë‹¤.\n* ì¿ ë²„ë„¤í‹°ìŠ¤ ê³µì‹ ë¬¸ì„œ - Control plane node isolation\n* Kubernetes Control-Plane Nodeì— Pod ë„ìš¸ìˆ˜ ìˆëŠ” ë°©ë²• (Taints)\nì°¸ê³  ì¿ ë²„ë„¤í‹°ìŠ¤(kubernetes) ì„¤ì¹˜ ë° í™˜ê²½ êµ¬ì„±í•˜ê¸°\n","id":3,"section":"posts","summary":"Kubernetes Cluster ì„¤ì¹˜í•˜ê¸° ì´ í˜ì´ì§€ì—ì„œëŠ” ubuntu18.04ì— kubeadm toolì„ ì„¤ì¹˜í•˜ê³  ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ kubernetes clusterë¥¼ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. êµ¬ì„± H/W êµ¬ì„±í•˜","tags":["docker","kubernetes"],"title":"Kubernetes Cluster ì„¤ì¹˜í•˜ê¸°(ubuntu18.04)","uri":"https://healinyoon.github.io/2020/09/20200828_install_kubernetes_cluster_ubuntu/","year":"2020"},{"content":"Pod Network pod networkê°€ í—·ê°ˆë ¤ì„œ ì •ë¦¬ìš©ìœ¼ë¡œ ë§Œë“  í˜ì´ì§€\nê³µì‹ ì‚¬ì´íŠ¸ì˜ ì„¤ëª…: Installing a Pod network add-on\n","id":4,"section":"posts","summary":"Pod Network pod networkê°€ í—·ê°ˆë ¤ì„œ ì •ë¦¬ìš©ìœ¼ë¡œ ë§Œë“  í˜ì´ì§€ ê³µì‹ ì‚¬ì´íŠ¸ì˜ ì„¤ëª…: Installing a Pod network add-on","tags":["kubernetes"],"title":"ì¿ ë²„ë„¤í‹°ìŠ¤ POD Network","uri":"https://healinyoon.github.io/2020/09/20200901_k8s_pod_network/","year":"2020"},{"content":"ëª©ì  Jenkins node heap memory ì‚¬ì´ì¦ˆ ë³€ê²½ ë°©ë²• ì •ë¦¬\nì°¸ê³  ìë£Œ  Java Memory Management for Java Virtual Machine (JVM) Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide CloudBees Jenkins JVM troubleshooting Jenkins ê¶Œì¥ ì‚¬ì–‘  Jenkins Heap Memory ì˜µì…˜ Jenkinsì—ì„œëŠ” ë‹¤ì–‘í•œ JAVA ì˜µì…˜ì„ ì¸ìˆ˜ë¡œ ë°›ì„ ìˆ˜ ìˆìŒ\nJenkins node heap memory ì‚¬ì´ì¦ˆë¥¼ ë³€ê²½í•˜ê¸° ìœ„í•œ ì¸ìˆ˜: -Xmxì™€ -Xms\n-Xms\u0026lt;size\u0026gt; set initial Java heap size -Xmx\u0026lt;size\u0026gt; set maximum Java heap size  ì˜ˆì‹œ 1) masterì˜ /etc/default/jenkinsì—ì„œ ì„¤ì • AVA_ARGS=\u0026quot;-Xmx256m\u0026quot; # default value JAVA_ARGS=\u0026quot;-Xmx2048m\u0026quot; # 2048MB size  2) Jenkins UIì—ì„œ slave ì„¤ì • [Jenkins ê´€ë¦¬] \u0026gt; [ë…¸ë“œ ê´€ë¦¬] \u0026gt; \u0026lsquo;ë…¸ë“œ ì„ íƒ í›„ ' [ì„¤ì •] \u0026gt; [ê³ ê¸‰] Jenkins ê¶Œì¥ ì‚¬ì–‘(ìì„¸íˆ) ì°¸ê³   It is recommended to define the same value for both -Xms and -Xmx so that the memory is allocated on startup rather than runtime. ëŒ€/ì†Œë¬¸ìëŠ” ìƒê´€ ì—†ìŒ(ì˜ˆ: -Xmx10GëŠ” -Xmx10gì™€ ë™ì¼í•¨) Java processes ì „ì—­ì— ì ìš©í•˜ê³  ì‹¶ìœ¼ë©´ JAVA_TOOL_OPTIONS í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©(ì˜ˆ: export JAVA_TOOL_OPTIONS=\u0026quot;-Xmx6g\u0026quot;)  ","id":5,"section":"posts","summary":"ëª©ì  Jenkins node heap memory ì‚¬ì´ì¦ˆ ë³€ê²½ ë°©ë²• ì •ë¦¬ ì°¸ê³  ìë£Œ Java Memory Management for Java Virtual Machine (JVM) Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide CloudBees Jenkins JVM troubleshooting Jenkins ê¶Œì¥ ì‚¬ì–‘ Jenkins Heap Memory ì˜µì…˜ Jenkinsì—ì„œëŠ” ë‹¤ì–‘í•œ JAVA ì˜µì…˜ì„ ì¸","tags":["jenkins"],"title":"Jenkins Node Heap Memory ì‚¬ì´ì¦ˆ ì„¤ì •í•˜ê¸°(-Xmx/-Xms ì˜µì…˜)","uri":"https://healinyoon.github.io/2020/08/20200831_jenkins_node_heap_size/","year":"2020"},{"content":"Jenkins Master-Slave JenkinsëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë‹¨ì¼ ì„œë²„ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¨ì¼ ì„œë²„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì„ ì¶©ì¡±í•˜ê¸° ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n ë¹Œë“œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ í™˜ê²½ì´ í•„ìš”í•œ ê²½ìš° í¬ê³  ë¬´ê±°ìš´ í”„ë¡œì íŠ¸ì˜ ì‘ì—… ë¶€í•˜ë¥¼ ë¶„ì‚°í•´ì•¼í•˜ëŠ” ê²½ìš°  ìœ„ì˜ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ê¸° ìœ„í•´ Jenknis ë¶„ì‚° ì•„í‚¤í…ì²˜ì¸ Master-Slave êµ¬ì„±ì´ ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤. Jenkins Masterì™€ Slaveì˜ ì—­í•     êµ¬ë¶„ ì—­í•      Master * Build ì‘ì—… ì˜ˆì•½* Build ì‹¤í–‰ì„ ìœ„í•œ ì‘ì—… ë¶„ë°°* Slave node ëª¨ë‹ˆí„°ë§(í•„ìš”ì— ë”°ë¼ on/offline ì „í™˜ ê°€ëŠ¥)* Build ê²°ê³¼ ê¸°ë¡   Slave * Jenkins Masterì˜ ìš”ì²­ ìˆ˜ì‹ * Build ì‹¤í–‰    Jenkins Master-Slave ì—°ë™ ë°©ë²• Jenkins Master-SlaveëŠ” ë‹¤ìŒì˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±ì‹œí‚¤ë©´ ë§¤ìš° ê°„ë‹¨í•˜ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n Master ì„œë²„ì—ì„œ Slave ì„œë²„ì— ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì • Slave ì„œë²„ì˜ Jenkins Java ìš”êµ¬ì‚¬í•­ ì¶©ì¡±  1. Jenkins ì‚¬ìš©ì ìƒì„±(ëª¨ë“  Slave nodeì—ì„œ ì§„í–‰) # adduser jenkins ì‚¬ìš©ì ìƒì„± í›„ ë‹¤ìŒê³¼ ê°™ì´ í™ˆë””ë ‰í† ë¦¬ì˜ ê¶Œí•œì„ ë³€ê²½í•´ì¤€ë‹¤ # chown ldccai:jenkins /home/jenkins # chmod 775 /home/jenkins  2. Java 8 ì„¤ì¹˜(ëª¨ë“  Slave nodeì—ì„œ ì§„í–‰) # apt-get install openjdk-8-jdk  3. Jenkinsì—ì„œ Slave node ë“±ë¡ ë“±ë¡ëœ ë…¸ë“œì˜ [ë¡œê·¸]ë¥¼ í™•ì¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ Master ì„œë²„ì™€ ì˜ ì—°ë™ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ","id":6,"section":"posts","summary":"Jenkins Master-Slave JenkinsëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë‹¨ì¼ ì„œë²„ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¨ì¼ ì„œë²„ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì„ ì¶©ì¡±í•˜ê¸° ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¹Œë“œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ í™˜ê²½ì´ í•„","tags":["jenkins"],"title":"Jenkins Master-Slave êµ¬ì„±í•˜ê¸°","uri":"https://healinyoon.github.io/2020/08/20200827_jenkins_master_slave/","year":"2020"},{"content":"CI/CDë€ CI/CDëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ ë‹¨ê³„ë¥¼ ìë™í™”í•˜ì—¬ ë³´ë‹¤ ì‘ì€ ì½”ë“œ ë‹¨ìœ„ì™€ ì§§ì€ ì£¼ê¸°ë¡œ Testì™€ Buildë¥¼ ìˆ˜í–‰í•˜ê³  ê³ ê°ì—ê²Œ ì œê³µí•˜ëŠ” ë°©ë²•ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\nCI(Continuous Integration): ì§€ì†ì  í†µí•© ê°œë°œìì˜ ë³€ê²½ ì‚¬í•­ì´ ì •ê¸°ì ìœ¼ë¡œ(ìµœìƒì˜ ê²½ìš° í•˜ë£¨ ì—¬ëŸ¬ë²ˆ) ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸ ë˜ê³  ê³µìœ  ë¦¬í¬ì§€í† ë¦¬ì— ë³‘í•©ë˜ëŠ” í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤.\nCD(Continous Deploy or ontinuous Delivery): ì§€ì†ì  ë°°í¬ Jez Humbleì˜ ì •ì˜\nContinuous Deployment is about automating the release of a good build to the production environment. In fact, Humble thinks it might be more accurate to call it â€œcontinuous release.â€\nContinuous Delivery is about 1) ensuring that every good build is potentially ready for production release. At the very least, 2) itâ€™s sent to the user acceptance test (UAT) environment. 3) Your business team can then decide when a successful build in UAT can be deployed to production â€”and they can do so at the push of a button.\nìƒí™©ì— ë”°ë¼ ì´ë¯¸ ìš´ì˜ë˜ê³  ìˆëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°”ë¡œ release í•˜ëŠ” ê²ƒì€ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ìš°ë¡œ ì„ë² ë””ë“œ ì†Œí”„íŠ¸ì›¨ì–´ ë“±ì´ í•´ë‹¹ë©ë‹ˆë‹¤.\në”°ë¼ì„œ ì ì¬ì ìœ¼ë¡œëŠ” release ê°€ëŠ¥í•˜ì§€ë§Œ, í”„ë¡œë•ì…˜ í™˜ê²½ì— ìë™ìœ¼ë¡œ release ë˜ì§€ ì•ŠëŠ” ê²ƒì´ Continuous Delivery ì…ë‹ˆë‹¤. ì •ë¦¬  CI: ì§€ì†ì ì¸ ë¹Œë“œ / í…ŒìŠ¤íŠ¸ / í†µí•© CD: CIì˜ ì—°ì¥ì„  ~ Release ì¤€ë¹„ ì™„ë£Œ(Delivery) or ì œí’ˆ ì¶œì‹œ(Deploy)   Jenkins for CI/CD ë‹¤ì–‘í•œ CI/CD tool CI/CD êµ¬í˜„ì„ ìœ„í•œ ë‹¤ì–‘í•œ toolì´ ìˆìŠµë‹ˆë‹¤. toolì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ ì°¸ê³ \nì™œ Jenkinsì¸ê°€ JenkinsëŠ” ì•„ë˜ì™€ ê°™ì€ ê°•ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n It is an open-source tool with great community support. It is easy to install. It has 1000+ plugins to ease your work. If a plugin does not exist, you can code it and share it with the community. It is free of cost. It is built with Java and hence, it is portable to all the major platforms.  í•˜ì§€ë§Œ ë‹¨ì  ì—­ì‹œ ì¡´ì¬í•©ë‹ˆë‹¤. CI/CD tool ì¤‘ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” Jenkins vs Gitlab vs Travis ë¹„êµ ê¸€ì„ ì°¸ê³ í•˜ì‹œë©´ Jenkinsì˜ ì¥ë‹¨ì ì„ ì´í•´í•˜ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n","id":7,"section":"posts","summary":"CI/CDë€ CI/CDëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ ë‹¨ê³„ë¥¼ ìë™í™”í•˜ì—¬ ë³´ë‹¤ ì‘ì€ ì½”ë“œ ë‹¨ìœ„ì™€ ì§§ì€ ì£¼ê¸°ë¡œ Testì™€ Buildë¥¼ ìˆ˜í–‰í•˜ê³  ê³ ê°ì—ê²Œ ì œê³µí•˜ëŠ” ë°©ë²•ì„ ì˜ë¯¸","tags":["jenkins"],"title":"CI/CDì™€ Jenkins","uri":"https://healinyoon.github.io/2020/08/20200827_cicd_and_jenkins/","year":"2020"},{"content":"HUGO ê¸€ ìƒì„±í•˜ê¸° $ hugo new {íŒŒì¼ëª…}  HUGO ë¸”ë¡œê·¸ ë¹Œë“œ $ hugo -t {í…Œë§ˆëª…}  Git push $ cd public $ git add . $ git commit -m \u0026quot;{commit ë©”ì„¸ì§€}\u0026quot; $ git push origin master $ cd .. $ git add . $ git commit -m \u0026quot;{commit ë©”ì„¸ì§€}\u0026quot; $ git push origin master  ","id":8,"section":"posts","summary":"HUGO ê¸€ ìƒì„±í•˜ê¸° $ hugo new {íŒŒì¼ëª…} HUGO ë¸”ë¡œê·¸ ë¹Œë“œ $ hugo -t {í…Œë§ˆëª…} Git push $ cd public $ git add . $ git commit -m \u0026quot;{commit ë©”ì„¸ì§€}\u0026quot; $ git push origin master $ cd .. $ git add . $ git commit -m \u0026quot;{commit ë©”","tags":["go","hugo"],"title":"HUGO ë¸”ë¡œê·¸ ìƒˆê¸€ ì—…ë¡œë“œí•˜ê¸°","uri":"https://healinyoon.github.io/2020/08/20200827_hugo_blog/","year":"2020"},{"content":"Intro ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” CentOSì— Dockerë¥¼ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\n 1. Docker ì„¤ì¹˜í•˜ê¸° # yum íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ yum update # docker, docker registry ì„¤ì¹˜ yum -y install docker docker-registry   2. Docker ì‹¤í–‰ ë° ì •ë³´ í™•ì¸ 2-1. Docker ì‹¤í–‰í•˜ê¸° # ì‹œìŠ¤í…œ ë¶€íŒ… ì‹œ dockerë¥¼ ì‹œì‘í•˜ë„ë¡ ì„¤ì • systemctl enable docker.service # Docker ì‹¤í–‰ systemctl start docker.service # Docker ìƒíƒœ í™•ì¸ systemctl status docker.service  2-2. Docker ëª…ë ¹ì–´ ì‚¬ìš©í•˜ê¸° Docker ëª…ë ¹ì–´ì˜ ê¸°ë³¸ í˜•ì‹ì€ docker {ëª…ë ¹ì–´} ì…ë‹ˆë‹¤.\n# Docker ë²„ì „ í™•ì¸ docker version # Docker ì‹¤í–‰ í™˜ê²½ í™•ì¸ docker system info # Docker ë””ìŠ¤í¬ ìƒíƒœ í™•ì¸ docker system df # ê·¸ ì™¸ Docker ëª…ë ¹ì–´ ì‚´í´ë³´ê¸° docker -help   3. Docker ì‚¬ìš©í•´ë³´ê¸° Dockerê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.\n3-1. Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰í•˜ê¸° # Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ëª…ë ¹ì–´ docker run {ì˜µì…˜} {ì»¨í…Œì´ë„ˆ ëª…/ID}  docker run ëª…ë ¹ì–´ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰ì‹œí‚¤ëŠ” ëª…ë ¹ì–´ ì…ë‹ˆë‹¤. ì´ë•Œ dockersëŠ” ë¡œì»¬ì— í•´ë‹¹ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í•™ì¸í•˜ê³ , ì—†ëŠ” ê²½ìš° docker hubì—ì„œ pullì„ ë¨¼ì € ì§„í–‰í•˜ê³  ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n3-2. Hello, world! docker run hello-world  hello-world ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë©”ì„¸ì§€ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\nHello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.  3-3. Nginx ì´ë²ˆì—ëŠ” Nginx ì›¹ì„œë²„ë¥¼ dockerë¡œ ì„¤ì¹˜í•´ë³´ê² ìŠµë‹ˆë‹¤.\n# Nginx ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ docker pull nginx # ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ í™•ì¸ docker images # Nginx ì»¨í…Œì´ë„ˆ ì‹¤í–‰ docker run --name nginx-webserver -d -p 80:80 nginx  docker run ëª…ë ¹ì–´ì—ì„œ ìì£¼ ì“°ì´ëŠ” ì˜µì…˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n \u0026ndash;name: ì»¨í…Œì´ë„ˆì˜ ì´ë¦„ì„ ì„¤ì •í•œë‹¤. -d: ì»¨í…Œì´ë„ˆë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ì‹œí‚¨ë‹¤. -p: í˜¸ìŠ¤íŠ¸ í¬íŠ¸ì™€ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ í¬íŠ¸ë¥¼ ë§¤í•‘í•œë‹¤(í˜•ì‹: -p {host í¬íŠ¸}:{ì»¨í…Œì´ë„ˆ í¬íŠ¸}).  ì‹¤í–‰ì¤‘ì¸ docker ì»¨í…Œì´ë„ˆë¥¼ í™•ì¸í•˜ê³  ì‹¶ì„ ë•ŒëŠ” docker ps ëª…ë ¹ì–´ë¡œ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n# ì‹¤í–‰ì¤‘ì¸ ì»¨í…Œì´ë„ˆ í™•ì¸ docker ps # ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸ docker container stats  ë§ˆì§€ë§‰ìœ¼ë¡œ http://localhost:80ìœ¼ë¡œ ì ‘ì†í•´ì„œ Nginx ì›¹ ë¸Œë¼ìš°ì €ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n ì°¸ê³  ì‚¬ì´íŠ¸  https://niceman.tistory.com/36 https://futurecreator.github.io/2018/11/16/docker-container-basics/ http://pyrasis.com/Docker/Docker-HOWTO  ","id":9,"section":"posts","summary":"Intro ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” CentOSì— Dockerë¥¼ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. 1. Docker ì„¤ì¹˜í•˜ê¸° # yum íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ yum update # docker, docker registry ì„¤ì¹˜ yum -y install docker docker-registry 2. Docker ì‹¤í–‰ ë°","tags":["docker"],"title":"Docker ì„¤ì¹˜í•˜ê¸°(CentOS)","uri":"https://healinyoon.github.io/2019/06/20190611_docker_install/","year":"2019"}],"tags":[{"title":"docker","uri":"https://healinyoon.github.io/tags/docker/"},{"title":"go","uri":"https://healinyoon.github.io/tags/go/"},{"title":"hugo","uri":"https://healinyoon.github.io/tags/hugo/"},{"title":"jenkins","uri":"https://healinyoon.github.io/tags/jenkins/"},{"title":"kubernetes","uri":"https://healinyoon.github.io/tags/kubernetes/"}]}